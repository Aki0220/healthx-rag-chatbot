from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.schema import HumanMessage, AIMessage

from config import *
from loaders.pdf_loader import load_pdfs
from utils.splitter import split_documents
from vectorstore.chroma_store import get_chroma_db
from chains.retriever import create_history_retriever
from chains.rag_chain import build_rag_chain

# =====================
# ğŸ”´ Session State åˆæœŸåŒ–ï¼ˆæœ€å„ªå…ˆï¼‰
# =====================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = None

if "retriever" not in st.session_state:
    st.session_state.retriever = None

# =====================
# ç”»é¢ã‚¿ã‚¤ãƒˆãƒ«
# =====================
st.title("HealthX RAG Chatbot")

# =====================
# RAG åˆæœŸåŒ–ï¼ˆ1å›ã ã‘ï¼‰
# =====================
if st.session_state.rag_chain is None:
    with st.spinner("è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        docs = load_pdfs(DATA_DIR)
        splitted_docs = split_documents(docs, CHUNK_SIZE, CHUNK_OVERLAP)

        # ğŸ” ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
        st.write("ğŸ“„ èª­ã¿è¾¼ã‚“ã PDFãƒšãƒ¼ã‚¸æ•°:", len(docs))
        st.write("âœ‚ï¸ åˆ†å‰²ãƒãƒ£ãƒ³ã‚¯æ•°:", len(splitted_docs))

        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small"
        )

        db = get_chroma_db(splitted_docs, embeddings, DB_DIR)

        retriever = db.as_retriever(
            search_kwargs={"k": 6}
        )
        st.session_state.retriever = retriever

        llm = ChatOpenAI(
            model_name=MODEL_NAME,
            temperature=TEMPERATURE
        )

        history_retriever = create_history_retriever(llm, retriever)
        st.session_state.rag_chain = build_rag_chain(
            llm,
            history_retriever
        )

# =====================
# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
# =====================
for msg in st.session_state.chat_history:
    if isinstance(msg, HumanMessage):
        st.write("ğŸ‘¤", msg.content)
    elif isinstance(msg, AIMessage):
        st.write("ğŸ¤–", msg.content)

# =====================
# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
# =====================
query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("é€ä¿¡") and query:
    # ğŸ” æ¤œç´¢çµæœç¢ºèª
    docs_found = st.session_state.retriever.get_relevant_documents(query)
    st.write("ğŸ” æ¤œç´¢ãƒ’ãƒƒãƒˆæ•°:", len(docs_found))

    if docs_found:
        st.write("ğŸ“„ æœ€åˆã®ãƒ’ãƒƒãƒˆå†…å®¹ï¼ˆæŠœç²‹ï¼‰:")
        st.write(docs_found[0].page_content[:300])

    # ğŸ¤– RAG å®Ÿè¡Œ
    result = st.session_state.rag_chain.invoke({
        "input": query,
        "chat_history": st.session_state.chat_history
    })

    answer = str(result["answer"])

    st.session_state.chat_history.extend([
        HumanMessage(content=query),
        AIMessage(content=answer)
    ])

    st.rerun()